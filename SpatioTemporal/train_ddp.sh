#!/bin/bash

# DDPËÆ≠ÁªÉËÑöÊú¨ - Â§öÂç°Êó∂Á©∫ÂØπÊØîÂ≠¶‰π† (SOTAÁ∫ßÂà´ÂÆûÁé∞)
# ‰ΩøÁî®ÊñπÊ≥ï:
#   bash train_ddp.sh                    # ‰ΩøÁî®ÈªòËÆ§GPU 0,1,2,3
#   bash train_ddp.sh "0,1,2,3"         # ÊåáÂÆöÁâπÂÆöGPU
#   bash train_ddp.sh "4,5,6,7"         # ‰ΩøÁî®ÂÖ∂‰ªñGPU

# GPUÈÖçÁΩÆ (ÂèØÈÄöËøáÁ¨¨‰∏Ä‰∏™ÂèÇÊï∞ÊåáÂÆö)
GPUS=${1:-"0,1"}  # ÈªòËÆ§‰ΩøÁî®GPU 0,1,2,3
export CUDA_VISIBLE_DEVICES=${GPUS}
NUM_GPUS=$(echo ${GPUS} | tr ',' '\n' | wc -l)

# Âü∫Á°ÄÂèÇÊï∞ (‰ΩøÁî®‰∏éÂéüËÑöÊú¨Áõ∏ÂêåÁöÑË∑ØÂæÑÂíåÂèÇÊï∞)
DATA_PATH="/hpc2hdd/home/qwang650/project/yutianjiang/stmodel/dataset/Guangzhou"
LOG_ROOT="/hpc2hdd/home/qwang650/project/yutianjiang/stmodel/training_results"
DATASET_NAME="STlabelScoreGroupDataset"
ARCH="resnet50"
BATCH_SIZE=20  # ÊØè‰∏™GPUÁöÑbatch size (‰∏éÂéüËÑöÊú¨‰∏ÄËá¥)
EPOCHS=100
LR=0.0003
WEIGHT_DECAY=1e-4
OUT_DIM=128

# ÂÆûÈ™åÈÖçÁΩÆ
MODE="group-spatial_temporal"
LOG_TAG="ddp_4gpu"
GROUP_ELEMENT=4
GROUP_NUM=${BATCH_SIZE}  # group_numÁ≠â‰∫ébatch_size

# ÊçüÂ§±ÊùÉÈáç (‰∏éÂéüËÑöÊú¨‰∏ÄËá¥)
SPATIAL_WEIGHT=0.3
TEMPORAL_WEIGHT=0.3
TEMPORAL_SOFT_WEIGHT=0.2
SPATIAL_TEMPORAL_WEIGHT=0.2

# ÂØπÊØîÂ≠¶‰π†ÂèÇÊï∞ (‰∏éÂéüËÑöÊú¨‰∏ÄËá¥)
NUM_NEG=6  # ‰∏éÂéüËÑöÊú¨‰∏ÄËá¥
TEMPERATURE=0.07
N_VIEWS=2
EPSILON=0.1

# ËÆ≠ÁªÉÂèÇÊï∞
WORKERS=12
WARMUP_EPOCHS=20
LOG_EVERY_N_STEPS=100
SEED=42

# WandbÈÖçÁΩÆ
WANDB_PROJECT="stmodel-guangzhou"

# LabelsÈÖçÁΩÆ (‰∏éÂéüËÑöÊú¨‰∏ÄËá¥)
LABELS_STR="['dense houses', 'trees', 'grass', 'river', 'barren land', 'sidewalks', 'farmland', 'tall buildings', 'soil', 'crop fields', 'roads']"

# ÂàõÂª∫ÂÆûÈ™åÂêçÁß∞
EXPERIMENT_NAME="guangzhou_spatiotemporal_ddp_$(date +%Y%m%d_%H%M)"

# SOTAÁ∫ßÂà´ÁöÑÈ™åËØÅÂíåÁõëÊéß
echo "======================================"
echo "üìä DDP Training Configuration (SOTA)"
echo "======================================"
echo "üî• GPUs: ${GPUS} (${NUM_GPUS} cards)"
echo "üìÅ Experiment: ${EXPERIMENT_NAME}"
echo "üíæ Data: ${DATA_PATH}"
echo "üìà Total effective batch size: $((BATCH_SIZE * NUM_GPUS * GROUP_ELEMENT * N_VIEWS))"
echo "üéØ Per GPU batch size: ${BATCH_SIZE}"
echo "üß† Contrastive Learning enhanced by ${NUM_GPUS}x negative samples"
echo "======================================"

# È™åËØÅGPUÂèØÁî®ÊÄß
echo "üîç Checking GPU availability..."
if ! command -v nvidia-smi &> /dev/null; then
    echo "‚ùå ERROR: nvidia-smi not found"
    exit 1
fi

nvidia-smi --query-gpu=index,name,memory.total,memory.used --format=csv,noheader,nounits | head -n ${NUM_GPUS}

# È™åËØÅÊï∞ÊçÆË∑ØÂæÑ
if [ ! -d "${DATA_PATH}" ]; then
    echo "‚ùå ERROR: Data path not found: ${DATA_PATH}"
    exit 1
fi

echo "‚úÖ All checks passed. Starting training..."

# ‰ΩøÁî®torchrunÂêØÂä®DDPËÆ≠ÁªÉ
torchrun \
    --standalone \
    --nproc_per_node=${NUM_GPUS} \
    run.py \
    --data ${DATA_PATH} \
    --dataset-name ${DATASET_NAME} \
    --arch ${ARCH} \
    --batch-size ${BATCH_SIZE} \
    --epochs ${EPOCHS} \
    --lr ${LR} \
    --out_dim ${OUT_DIM} \
    --log_root ${LOG_ROOT} \
    --experiment-name ${EXPERIMENT_NAME} \
    --MODE ${MODE} \
    --log_tag ${LOG_TAG} \
    --group_num ${GROUP_NUM} \
    --group_element ${GROUP_ELEMENT} \
    --spatial-weight ${SPATIAL_WEIGHT} \
    --temporal-weight ${TEMPORAL_WEIGHT} \
    --temporal-soft-weight ${TEMPORAL_SOFT_WEIGHT} \
    --spatial-temporal-weight ${SPATIAL_TEMPORAL_WEIGHT} \
    --lambda_temporal ${LAMBDA_TEMPORAL} \
    --num_neg ${NUM_NEG} \
    --temperature ${TEMPERATURE} \
    --n-views ${N_VIEWS} \
    --wandb-project ${WANDB_PROJECT} \
    --world-size ${NUM_GPUS} \
    --workers 8 \
    --seed 42 \
    --mixed-precision \
    --cuda

echo "======================================"
echo "DDP Training completed!"
echo "Logs saved in: ${LOG_ROOT}/${EXPERIMENT_NAME}"
echo "======================================"